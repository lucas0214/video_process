from openai import OpenAI
import os
import requests
import cv2
import base64
import json
import os
from io import BytesIO

import numpy as np
from tqdm import tqdm

try:
    from decord import VideoReader, cpu
except ImportError:
    pass
from PIL import Image


def write_json(json_path, information_video):
    with open(json_path, 'a', encoding='utf-8') as file:
        json.dump(information_video, file, ensure_ascii=False, indent=4)


def encode_video(video_path, for_get_frames_num):
    vr = VideoReader(video_path, ctx=cpu(0))
    total_frame_num = len(vr)
    uniform_sampled_frames = np.linspace(0, total_frame_num - 1, for_get_frames_num, dtype=int)

    # Ensure the last frame is included
    if total_frame_num - 1 not in uniform_sampled_frames:
        uniform_sampled_frames = np.append(uniform_sampled_frames, total_frame_num - 1)

    frame_idx = uniform_sampled_frames.tolist()
    frames = vr.get_batch(frame_idx).asnumpy()

    base64_frames = []
    for frame in frames:
        img = Image.fromarray(frame)
        output_buffer = BytesIO()
        img.save(output_buffer, format="PNG")
        byte_data = output_buffer.getvalue()
        base64_str = base64.b64encode(byte_data).decode("utf-8")
        base64_frames.append(base64_str)

    return base64_frames


def request_4o(client, video_path, base64Frames, addition_info, q, o, pred_answer, gt_answer):
    data_dict = {}
    data_dict["video_path"] = video_path
    data_dict["contexts"] = addition_info
    data_dict["question"] = q
    data_dict["options"] = o
    data_dict["4o_answer"] = pred_answer
    data_dict["gt"] = gt_answer

    message = [
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": addition_info,
                }
            ]
        }
    ]
    for base64_image in base64Frames:
        a = {
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{base64_image}"
            },
        }
        message[0]["content"].append(a)

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=message,
        max_tokens=300,
    )
    result = response.choices[0].message.content

    data_dict["our_answer"] = result

    return data_dict


def process_video(video_dict, question, q, o, pred_answer, gt_answer):
    # 初始化 openai client

    base64_frames = encode_video(video_dict["input_video"], 32)

    additions = "The specific details we can provide about this video_shot are: "
    for video_clip in video_dict["clips"]:
        additions = str(additions) + "From " + str(video_clip["start_time"]) + " to " + str(video_clip["end_time"]) + ", the result of OCR is " + str(video_clip["ocr"]) + ", the content of the video_shot captions generated by combining the OCR results of the video_shot is " + str(video_clip["ocr_caption"][0]) + " "

    additions = str(additions) + str(question)

    our_answer = request_4o(client, video_dict["input_video"], base64_frames, additions, q, o, pred_answer, gt_answer)   # dict

    return our_answer


if __name__ == '__main__':
    with open("/opt/dlami/nvme/ocr_4o/data/text/captions.json", "r") as f:
        ocr_data = json.load(f)

    with open("/opt/dlami/nvme/ocr_4o/data/text/4o_OCR_error.json", "r") as f:
        error_data = json.load(f)

    our_answer_list = []
    for ocr_da in tqdm(ocr_data):
        video = ocr_da["input_video"]
        video_basename = os.path.basename(video).split(".")[0]

        for error in error_data:
            if error["videoID"] == video_basename:
                our_answer_dict = process_video(ocr_da, error["input"], error["question"], error["options"], error["pred_answer"], error["answer"])
                our_answer_list.append(our_answer_dict)

    write_json("/opt/dlami/nvme/ocr_4o/data/text/predict_our_method/our_ocr_4o.json", our_answer_list)


